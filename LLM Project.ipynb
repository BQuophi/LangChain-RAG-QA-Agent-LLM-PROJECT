{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4baa76cb-6e4e-44b7-bcc2-5e5bfa7161e6",
   "metadata": {},
   "source": [
    "## Library Installations\n",
    "\n",
    "The code below installs the necessary Python libraries required for building and running a question-and-answer agent using LangChain, IBM Watsonx AI, and other supporting tools. Each library is installed using the pip package manager. The | tail -n 1 part ensures only the last line of the installation output is displayed, keeping the output concise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "badbb21d-abae-42df-8565-67c305e7805f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: jsonpointer>=1.9 in /opt/conda/lib/python3.11/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3.0,>=0.2.10->langchain==0.2.6) (2.4)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /opt/conda/lib/python3.11/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community==0.2.6) (1.0.0)\n",
      "Requirement already satisfied: six>=1.10.0 in /opt/conda/lib/python3.11/site-packages (from lomond->ibm-watsonx-ai==1.0.10) (1.16.0)\n",
      "Requirement already satisfied: six>=1.10.0 in /opt/conda/lib/python3.11/site-packages (from lomond->ibm-watsonx-ai<2.0.0,>=1.0.8->langchain_ibm==0.1.8) (1.16.0)\n",
      "Requirement already satisfied: wget==3.2 in /opt/conda/lib/python3.11/site-packages (3.2)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.11/site-packages (from sympy->torch>=1.11.0->sentence-transformers==3.0.1) (1.3.0)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /opt/conda/lib/python3.11/site-packages (from pyasn1-modules>=0.2.1->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb==0.5.3) (0.6.0)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in /opt/conda/lib/python3.11/site-packages (from pydantic==2.8.0) (4.11.0)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /opt/conda/lib/python3.11/site-packages (from sqlalchemy==2.0.30) (3.0.3)\n"
     ]
    }
   ],
   "source": [
    "!pip install langchain==0.2.6 | tail -n 1\n",
    "!pip install langchain-community==0.2.6 | tail -n 1\n",
    "!pip install ibm-watsonx-ai==1.0.10 | tail -n 1\n",
    "!pip install langchain_ibm==0.1.8 | tail -n 1\n",
    "!pip install wget==3.2 | tail -n 1\n",
    "!pip install sentence-transformers==3.0.1 | tail -n 1\n",
    "!pip install chromadb==0.5.3 | tail -n 1\n",
    "!pip install pydantic==2.8.0 | tail -n 1\n",
    "!pip install sqlalchemy==2.0.30 | tail -n 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a234bb3d-f332-4153-8f4e-7ee9233ea194",
   "metadata": {},
   "source": [
    "## Initializing IBM Watsonx AI Client\n",
    "\n",
    "This code sets up the IBM Watsonx AI client by initializing the necessary credentials and creating a client instance. This client will be used to interact with IBM's machine learning services.\n",
    "\n",
    "To learn more on how to get your credentials from IBM Cloud, follow the instructions in the link below under `Creating an API key in the console`\n",
    "https://cloud.ibm.com/docs/account?topic=account-userapikey&interface=ui\n",
    ".You might have to create an IBM Cloud Account, if you haven't already.\n",
    "\n",
    "Or follow the guided project from IBMSKillsBuild Here to run the project lab in an already provided environment. - https://cognitiveclass.ai/courses/build-a-grounded-q-a-agent-with-langchain-granite-and-rag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "513e94b0-114e-4181-a370-c54483eff421",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary modules from the ibm_watsonx_ai library\n",
    "from ibm_watsonx_ai import APIClient\n",
    "from ibm_watsonx_ai import Credentials\n",
    "import os\n",
    "\n",
    "# Initialize the credentials with the specified URL for IBM Watsonx AI service\n",
    "credentials = Credentials(\n",
    "    url = \"https://us-south.ml.cloud.ibm.com\",  # IBM Watsonx AI service URL\n",
    "    # The api_key parameter would typically be added here to authenticate the client\n",
    "    # api_key = os.getenv('IBM_WATSON_API_KEY')  # Example of fetching API key from environment variables\n",
    ")\n",
    "\n",
    "# Create an API client using the initialized credentials\n",
    "client = APIClient(credentials)\n",
    "\n",
    "# Set the project ID for the specific IBM Watsonx project\n",
    "project_id = \"skills-network\"  # Project identifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff633b75-e509-4514-a28c-13d0d6f74d3e",
   "metadata": {},
   "source": [
    "## Loading and Splitting Text Documents\n",
    "\n",
    "This code downloads a text file if it does not exist locally, loads the document using LangChain's TextLoader, and then splits the document into chunks using CharacterTextSplitter. This is useful for processing large text documents in smaller, manageable pieces."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6878c87f-a64e-4d02-9b65-0fb4f0b23534",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of chunks: 2\n"
     ]
    }
   ],
   "source": [
    "# Import necessary modules\n",
    "import requests  # Import the requests module to handle HTTP requests\n",
    "from langchain.document_loaders import TextLoader  # Import TextLoader from LangChain to load text documents\n",
    "from langchain.text_splitter import CharacterTextSplitter  # Import CharacterTextSplitter to split text into chunks\n",
    "\n",
    "# Define filename and URL\n",
    "filename = 'text.txt'  # Name of the file to be downloaded and saved locally\n",
    "url = 'Independent Labs/Build a grounded Q/text.txt'  # URL of the file to be downloaded. Provide your own url according to the file location path\n",
    "\n",
    "# Download the file if it does not exist\n",
    "if not os.path.isfile(filename):  # Check if the file does not exist locally\n",
    "    response = requests.get(url)  # Send a GET request to the specified URL\n",
    "    with open(filename, 'wb') as f:  # Open the file in write-binary mode\n",
    "        f.write(response.content)  # Write the content of the response to the file\n",
    "\n",
    "# Load the document\n",
    "loader = TextLoader(filename)  # Initialize the TextLoader with the filename\n",
    "documents = loader.load()  # Load the document into a variable\n",
    "\n",
    "# Split the document into chunks using CharacterTextSplitter\n",
    "text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)  # Initialize CharacterTextSplitter with chunk size of 1000 characters and no overlap\n",
    "texts = text_splitter.split_documents(documents)  # Split the loaded documents into chunks\n",
    "\n",
    "# Print the number of chunks created\n",
    "print(f\"Number of chunks: {len(texts)}\")  # Output the number of chunks created"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50d509c0-3804-4625-be55-754681a20542",
   "metadata": {},
   "source": [
    "### Creating and Storing Embeddings with Watsonx and Chroma\n",
    "\n",
    "Now let's set up an embedding model using IBM Watsonx AI, embeds documents using this model, and stores these embeddings in a Chroma vector store. It also prints sample embedding vectors for a subset of the documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ab07a617-a1d9-4a1d-9c66-11cb09d40286",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample Embedding Vectors:\n",
      "Document 1 Embedding Vector: Length: 384; [0.014287684, -0.018624494, 0.10425287, 0.009707264, 0.044396505, 0.034498498, -0.0011637486, -0.019179942, 0.045551687, 0.009745523, -0.008944669, -0.009076451, 0.0029893608, 0.020455262, -0.051753055, 0.15330191, 0.02954992, 0.0012786002, 0.012898027, -0.019495677, -0.010997851, -0.104380496, 0.024528699, 0.0018810942, 0.04237788, 0.085882865, 0.03287752, 0.00547694, 0.03549624, 0.07000522, 0.02362027, 0.008426686, 0.082991414, 0.0055107134, 0.08932523, 0.0149316825, 0.07735054, 0.03059676, 0.052171387, -5.2096216e-06, 0.0052892324, 0.010849655, 0.001597183, -0.0033374417, 0.11880174, 0.05441545, 0.039025236, -0.020059828, 0.04031473, 0.00061696453, 0.036925007, 0.097642355, 0.05062332, 0.052106366, 0.023463836, 0.0132824015, 0.050097454, -0.0021754769, 0.025557738, 0.02594622, 0.016432146, 0.122749515, 0.02371394, -0.025632314, 0.043104425, -0.016782181, -0.047486678, 0.0045230095, 0.0420029, 0.04656813, 0.0301889, 0.050694376, 0.052325457, 0.062150083, 0.035698354, 0.06489579, -0.01710639, -0.057241935, 0.059225943, -0.014429742, 0.05893595, 0.042662505, 0.029240217, 0.0028838234, 0.011416267, 0.0058008158, 0.03276078, -0.006899474, 0.019426642, 0.042276435, -0.051951446, 0.030216701, 0.13334244, 0.066347785, -0.028478308, 0.025940137, 0.03644613, 0.017077323, -0.32826242, 0.0021588183, -0.032906115, 0.018166073, -0.0016155714, -0.0063776383, 0.033657394, 0.09570777, -0.013543391, 0.06174397, 0.032091707, -0.00322244, 0.008210319, 0.045147106, -0.015995005, -0.03439254, 0.008496799, 0.09173104, 0.04143178, -0.019376127, -0.002155901, -0.0132708885, -0.0010990914, 0.04587725, 0.017840324, -0.038426682, 0.05557753, 0.011467516, 0.0101494, -0.002744685, -0.013957573, -0.07724992, 0.029918423, -0.0014601727, -0.03190573, 0.05535588, 0.031274322, 0.008985911, 0.040666636, 0.022275794, 0.010887089, 0.018180419, -0.14417239, -0.14813362, 0.021866167, -0.01790289, 0.093767695, 0.008099132, 0.013447874, 0.0025505268, -0.0039662346, 0.011420331, 0.015002515, 0.026485045, 0.039884776, 0.035618145, 0.018151512, 0.060189404, -3.2318752e-05, -0.030400615, 0.04975716, 0.017722087, 0.06908196, 0.008909331, -0.012603026, -0.037309345, 0.14782065, 0.013403113, 0.06730729, 0.04142006, 0.0038993214, -0.0034493967, 0.0042352374, -0.03537878, -0.0019328973, -0.029185236, -0.031954844, 0.061572473, 0.019719679, 0.051411275, 0.082773186, 0.013432652, -0.0009827714, 0.043989576, -0.12573534, 0.0279544, -0.0154448915, 0.02841571, 0.009450008, -0.029482001, 0.04986725, 0.029622301, 0.023405991, 0.0039053764, 0.027316943, -0.009444878, -0.020715123, -0.10235493, 0.19566199, -0.003520622, 0.051837493, -0.0024785618, 0.01698213, 0.01938544, 0.0998587, -0.009603405, 0.005065698, 0.03237594, 0.035699364, 0.023086276, 0.043526012, 0.045029927, 0.07046566, -0.029185217, -0.0018203829, 0.027416615, 0.008329978, 0.031040095, 0.02479411, 0.094236, -0.0012185642, 0.02247064, 0.013651371, -0.030567873, -0.041212585, -0.052043274, 0.05749736, -0.00779417, 0.08368406, 0.04404845, 0.0054759397, 0.03488738, 0.024690935, -0.017397393, -0.21350682, -0.06550236, -0.029377576, 0.04954926, 0.0135183735, 0.019252276, -0.011253214, 0.014836021, 0.06955097, 0.016729835, 0.027899094, 0.03782407, 0.010703341, -0.0819375, 0.036219537, -0.049628247, 0.05348294, 0.01982141, -0.010490034, 0.015010437, 0.029218648, 0.0719063, 0.010223453, 0.0099435, 0.049881354, 0.034379963, -0.00069315557, 0.028746726, 0.08861483, 0.02646753, 0.023305954, 0.05442478, 0.061660454, 0.0018435331, 0.024503404, 0.020516852, 0.015270136, 0.052695632, 0.058833305, 0.021991353, 0.014020897, -0.06711673, 0.020448886, -0.0010432631, 0.07193916, 0.024427801, 0.042064734, 0.037742108, 0.041780476, 0.047196526, 0.031256344, -0.11435226, 0.052100126, -0.005130894, 0.04498195, 0.023039697, 0.0063395677, 0.054836616, 0.014327756, 0.058272224, 0.0020981303, -0.047976296, -0.010341626, 0.0056233527, 0.009105148, -0.020445826, -0.02841847, -0.0026402888, 0.01297026, 0.026018914, 0.041057613, -0.055253893, 0.0037580172, 0.025586843, 0.03070483, 0.0441912, 0.049608253, 0.03456354, 0.04732482, 0.019242484, 0.038459506, 0.05119801, 0.111987986, -0.11339411, 0.049366586, 0.019336054, -0.10173572, 0.022922913, -0.03212865, -0.023593035, -0.062025525, 0.04572671, 0.021959815, 0.014280602, 0.018755013, 0.039267257, -0.113639705, -0.050955757, 0.07641836, 0.02430827, 0.046334792, -0.056543875, 0.17672126, 0.023851458, 0.07226956, -0.09969058, 0.04312872, 0.030876938, 0.014406814, 0.05889806, 0.02651183, -0.040765397, 0.04963725, 0.02280281, 0.00015579995, -0.009408475, 0.07529024, 0.0062666233, 0.04021314, 0.005997345, 0.0044487664, -0.054175552, -0.099129066, -0.008441561, 0.005530797, 0.009036928, 0.045368046, -0.001728262, 0.021168713, -0.06834854, -0.034707382, 0.0034410884, -0.027504768, 0.012867864, 0.06404451, -0.03594346, 0.030646766, 0.021972325, 0.017710702, -0.099779025, -0.024275128, -0.008374049, -0.003846605, 0.044662356, -0.0024460887, -0.013700367, -0.015315698, 0.007616813, -0.011909201, 0.0053980164, 0.028365603, 0.023039166]\n",
      "Document 2 Embedding Vector: Length: 384; [0.057201106, 0.0070110424, 0.07412952, 0.005012461, 0.043192282, 0.024672693, -0.027650423, -0.017997237, 0.029159775, -0.007767963, -0.012956678, 0.019355837, -0.009520262, 0.032398082, -0.032326043, 0.11480627, -0.028195908, -0.01824454, 0.0058297506, -0.0004243055, -0.021202747, -0.10589909, 0.019809877, -0.0027467741, 0.023411212, 0.05493476, 0.011980704, -0.022551076, 0.003482242, 0.07049494, 0.043950956, 0.020037265, 0.0745854, 0.02939967, 0.032494582, -0.004416415, 0.052077334, 0.0406307, 0.07697442, 0.012604175, -0.03659508, 0.007677201, 0.0021816168, 0.023711812, 0.12672643, 0.02417952, 0.0016873771, -0.028779048, -0.008169441, 0.014181696, 0.031732112, 0.09547315, 0.0026528693, 0.018245652, 0.036103196, 0.034619708, 0.09909457, 0.015312222, -0.03168634, 0.014664447, 0.055141177, 0.11143896, 0.02512438, -0.017979795, 0.05330147, -0.010425784, -0.0535577, 0.022685276, 0.042065788, 0.02722661, 0.013700828, 0.05764848, 0.022305511, 0.045832943, 0.01293782, 0.059612297, -0.05557427, -0.028512137, 0.02334989, 0.019181333, 0.056656092, 0.036861014, 0.019287368, 0.00654047, 0.011037039, 0.022800904, 0.059634496, -0.020708315, -0.0030447694, 0.05376218, -0.081715345, 0.017845849, 0.12527111, 0.07408938, -0.018342283, 0.005676038, 0.053934433, 0.037670787, -0.37740797, -0.017005498, 0.02252411, 0.014814037, 0.03063727, -0.007612956, 0.058064613, 0.116507255, 0.0052673602, 0.06125645, 0.046330415, -0.015680347, 0.03207143, 0.057646543, 0.031366277, 0.017614517, 0.013529138, 0.05533736, 0.024303718, 0.008084509, 0.0355042, 0.014812268, 0.007044123, 0.044039447, -0.018015547, -0.016265031, 0.068455316, -0.025501393, 0.03182919, -0.007112996, -0.0062679676, -0.0317134, 0.041118674, -0.00089701, 0.02356024, -0.0026316182, 0.031226072, 0.0543924, 0.046793725, 0.018679064, 0.0063684345, 0.028112864, -0.14198661, -0.116402134, 0.034969445, 0.05445309, 0.0921786, -0.0094769, -0.004062758, 0.0107776625, 0.0040503955, 0.017895652, 0.025627827, 0.01761948, 0.018542498, 0.008754353, -0.024166437, 0.0066843275, 0.017448545, 0.018706746, 0.057074588, 0.009024934, 0.060765557, -0.010693845, 0.01741528, -0.047744256, 0.09849592, -0.0022960277, 0.07616002, 0.016266152, 0.003636898, -0.026195405, -0.010380968, 0.025326287, 0.03246837, -0.056536417, -0.010711007, 0.039985064, 0.027454356, 0.040790603, 0.034814622, 0.030957084, -0.007034006, 0.04372547, -0.12756787, 0.0032712768, 0.0039446424, 0.007670223, 0.014368736, -0.027785033, 0.025181415, 0.034669816, -0.001621912, -0.015190029, 0.031317804, 0.034659047, 0.00061282323, -0.07359397, 0.14964059, 0.01634194, 0.027871463, -0.052017447, -0.0018365153, 0.03960251, 0.09011911, -0.002334808, -0.020660503, 0.06379977, 0.008291472, 0.070464574, -0.0014455176, 0.040874887, 0.051596493, -0.0053350218, 0.056764536, 0.0128570115, -0.01904872, 0.008825845, 0.024734223, 0.068438336, -0.018701727, -0.013872945, -0.031426627, -0.047109786, 0.0028132168, -0.08843514, 0.06966277, 0.010177163, 0.059292164, 0.08713034, -0.002962945, 0.032632686, 0.025103407, -0.0064469813, -0.27850568, -0.02054575, -0.0028183344, 0.07361294, 0.027146451, -0.036493376, -0.014362044, 0.03168555, 0.045819897, 0.032118976, 0.01268826, 0.06774957, 0.039794683, -0.06469146, 0.03457064, -0.002567833, 0.026967926, 0.03354942, -0.014057607, 0.024600053, 0.04713084, 0.0642152, 0.010980227, 0.00967544, 0.03693565, 0.016780348, 0.0322474, 0.018940583, 0.064055234, 0.025643436, 0.044677306, 0.0083709555, 0.055728164, 0.03770777, -0.0055231876, 0.011586477, 0.011454036, 0.056296594, -0.004843755, 0.018360676, 0.032193996, -0.054784197, -0.0038715114, -0.007613163, 0.06458902, 0.03529869, 0.037546698, 0.03488162, 0.045902215, 0.058799993, 0.002891076, -0.12577556, 0.012104147, 0.015629327, 0.030027738, -0.0031775665, -0.012262977, 0.011265279, 0.015364062, 0.05559823, 0.0042425455, -0.038588803, 0.01875587, -0.019256182, -0.02076247, -0.019371932, 0.017082464, 0.027151126, -0.0076147364, 0.022439372, 0.047016703, -0.058213606, 0.01973149, 0.006424974, 0.05110724, 0.015713751, 0.036060493, -0.0031774612, 0.06531432, 0.07516151, 0.035103645, 0.052292276, 0.058664408, -0.12235205, 0.056530394, 0.030748868, -0.04767982, 0.015417229, -0.020792412, -0.024556339, 0.0005732875, 0.08686776, 0.035989232, 0.061556563, 0.013715551, 0.065804526, -0.06479687, -0.075251296, 0.08478978, 0.026528021, 0.021683535, -0.0766692, 0.19234909, 0.07940313, 0.09051318, -0.013633112, 0.0411632, 0.024625666, 0.07188089, 0.04570905, 0.035617188, -0.031421423, 0.039066557, 0.009663147, -0.012857142, -0.026293986, 0.0108334655, -0.006278133, 0.04716649, 0.01307447, 0.02845, 0.05221538, -0.11887395, -0.0085063735, 0.026884079, -0.0062613892, 0.07379479, 0.0066074915, 0.01798573, -0.064484015, -0.054441586, 0.00463373, 0.0069598802, 0.025325155, 0.06521726, -0.032104794, 0.028531412, -0.009269318, -0.00024621826, -0.12361772, -0.01202119, -0.0007682782, 0.044477966, 0.005338731, 0.00610123, -0.03640586, 0.052027192, 0.03583831, 0.04945164, 0.013869246, 0.015935922, 0.017098188]\n"
     ]
    }
   ],
   "source": [
    "# Import necessary modules\n",
    "from ibm_watsonx_ai.foundation_models.utils import get_embedding_model_specs  # Import utility to get embedding model specifications\n",
    "from langchain_ibm import WatsonxEmbeddings  # Import WatsonxEmbeddings class from langchain_ibm\n",
    "from ibm_watsonx_ai.foundation_models.utils.enums import EmbeddingTypes  # Import enumeration of embedding types\n",
    "from langchain.vectorstores import Chroma  # Import Chroma vector store from LangChain\n",
    "\n",
    "# Retrieve and print embedding model specifications\n",
    "get_embedding_model_specs(credentials.get('url'))  # Retrieve and print embedding model specifications from the IBM Watsonx AI service\n",
    "\n",
    "# Part 1: Create Embedding Model\n",
    "# Set up the WatsonxEmbeddings object\n",
    "embeddings = WatsonxEmbeddings(\n",
    "    model_id=EmbeddingTypes.IBM_SLATE_30M_ENG.value,  # Specify the model ID for the embedding model\n",
    "    url=credentials[\"url\"],  # URL for the IBM Watsonx AI service\n",
    "    project_id=project_id  # Project ID for the specific IBM Watsonx project\n",
    ")\n",
    "\n",
    "# Part 2: Embed Documents and Store\n",
    "# Embed the documents and store the embeddings in Chroma vector store\n",
    "docsearch = Chroma.from_documents(texts, embeddings)  # Embed the documents and store the embeddings in Chroma vector store\n",
    "\n",
    "# Let us print several embedding vectors.\n",
    "# Generate and print embedding vectors for a sample of the documents\n",
    "sample_texts = texts[:3]  # Taking a sample of 3 documents for demonstration\n",
    "sample_embeddings = embeddings.embed_documents([doc.page_content for doc in sample_texts])  # Generate embeddings for the sample documents\n",
    "\n",
    "# Print the sample embedding vectors\n",
    "print(\"Sample Embedding Vectors:\")\n",
    "for i, embedding in enumerate(sample_embeddings):  # Iterate over the sample embeddings\n",
    "    print(f\"Document {i + 1} Embedding Vector: Length: {len(embedding)}; {embedding}\")  # Print the length and the embedding vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "53a2a9c5-89f6-40ac-8885-db7ebeb4ea49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# help(WatsonxEmbeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e80e8bf-ffef-4b0c-a70f-3b28a2ff358a",
   "metadata": {},
   "source": [
    "## Setting Up the Model ID for IBM Watsonx AI\n",
    "\n",
    "This code sets the model_id to specify which model type to use from the ModelTypes enumeration provided by IBM Watsonx AI. In this case, it selects the GRANITE_13B_CHAT_V2 model, which is suited for conversational AI tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c51c0bc4-856a-4c38-9430-e38c75992485",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the ModelTypes enumeration from the ibm_watsonx_ai library\n",
    "from ibm_watsonx_ai.foundation_models.utils.enums import ModelTypes\n",
    "\n",
    "# Set the model_id to a specific model type from the ModelTypes enumeration\n",
    "model_id = ModelTypes.GRANITE_13B_CHAT_V2  # Selects the GRANITE_13B_CHAT_V2 model for chat applications"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d474089-cf2c-4f1c-a973-1cd3b708454f",
   "metadata": {},
   "source": [
    "### Configuring Parameters for Text Generation with IBM Watsonx AI\n",
    "\n",
    "This code sets up a dictionary of parameters used for configuring text generation tasks in IBM Watsonx AI. It specifies the decoding method, token limits, and stop sequences to control how the model generates text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7fe2f9fe-87fd-4221-866c-7f8127270eb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary modules for configuring text generation parameters\n",
    "from ibm_watsonx_ai.metanames import GenTextParamsMetaNames as GenParams  # Import parameter names for text generation\n",
    "from ibm_watsonx_ai.foundation_models.utils.enums import DecodingMethods  # Import available decoding methods\n",
    "\n",
    "# Define parameters for text generation\n",
    "parameters = {\n",
    "    GenParams.DECODING_METHOD: DecodingMethods.GREEDY,  # Set decoding method to Greedy, which selects the most likely next token\n",
    "    GenParams.MIN_NEW_TOKENS: 1,  # Minimum number of new tokens to generate\n",
    "    GenParams.MAX_NEW_TOKENS: 100,  # Maximum number of new tokens to generate\n",
    "    GenParams.STOP_SEQUENCES: [\"\\n\"],  # Stop generating tokens when encountering a newline character\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38877ba0-8cfd-44d3-a43c-6acec5ca5841",
   "metadata": {},
   "source": [
    "## Setting Up IBM Watsonx LLM with Configuration Parameters\n",
    "\n",
    "This code initializes a WatsonxLLM object from the langchain_ibm library using specific configuration parameters. This setup is used to interact with the IBM Watsonx AI model, specifically the GRANITE_13B_CHAT_V2 model, and apply the defined text generation parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b477b7e6-7427-4f34-b0b9-093280384598",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the WatsonxLLM class from the langchain_ibm library\n",
    "from langchain_ibm import WatsonxLLM  # Import the class that allows interaction with IBM Watsonx LLM\n",
    "\n",
    "# Initialize the WatsonxLLM object with the specified configuration\n",
    "watsonx_granite = WatsonxLLM(\n",
    "    model_id=model_id.value,  # Set the model ID to GRANITE_13B_CHAT_V2, which is a specific pre-trained model\n",
    "    url=credentials.get(\"url\"),  # Provide the URL for the IBM Watsonx AI service endpoint\n",
    "    project_id=project_id,  # Specify the project ID to use with the model\n",
    "    params=parameters  # Pass the text generation parameters defined earlier (e.g., decoding method, token limits)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00feac8b-3449-48d4-9595-bdc750f2ea94",
   "metadata": {},
   "source": [
    "## Creating a Retrieval-Based Question-Answering Chain\n",
    "\n",
    "This code initializes a RetrievalQA chain from the langchain library. It sets up a question-answering system that uses the watsonx_granite language model and a document retriever to answer questions based on a retrieval-augmented approach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fff38512-1249-438c-82b8-3b54fee185b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the RetrievalQA class from langchain.chains\n",
    "from langchain.chains import RetrievalQA\n",
    "\n",
    "# Initialize the RetrievalQA chain\n",
    "qa = RetrievalQA.from_chain_type(\n",
    "    llm=watsonx_granite,  # The WatsonxLLM instance to use for generating answers\n",
    "    chain_type=\"stuff\",  # Specifies the type of chain; \"stuff\" indicates a basic retrieval-based QA setup\n",
    "    retriever=docsearch.as_retriever()  # Document retriever to fetch relevant documents for answering questions\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79b38ef8-b718-421f-8505-4423c2025743",
   "metadata": {},
   "source": [
    "## Performing a Query with the Retrieval-Based QA System\n",
    "\n",
    "This code snippet demonstrates how to use the RetrievalQA chain to answer a specific query. The query is passed to the qa object (the initialized RetrievalQA chain), which utilizes the configured document retriever and language model to generate an answer.\n",
    "\n",
    "Explanation:\n",
    "- Importing RetrievalQA:\n",
    "\n",
    "RetrievalQA is a class in the langchain library that combines document retrieval with a question-answering model to answer questions based on retrieved documents.\n",
    "Initializing RetrievalQA:\n",
    "\n",
    "- llm: The large language model instance (watsonx_granite) used to generate responses to queries.\n",
    "- chain_type: Specifies the type of QA chain to use. \"stuff\" indicates a basic retrieval-based QA system where documents are retrieved and then used to generate answers.\n",
    "- retriever: The document retriever (docsearch.as_retriever()) that fetches relevant documents based on the input query, which are then used by the LLM to generate answers.\n",
    "\n",
    "\n",
    "This setup creates a question-answering system that leverages both document retrieval and a language model to provide accurate answers to user queries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "be1e6d92-0041-4500-8051-d82f08b0b1b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Number of requested results 4 is greater than number of elements in index 2, updating n_results = 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'query': 'What did Emma share with the children during their visit?', 'result': ' Emma shared stories about her experiences gardening with her grandmother.\\n'}\n"
     ]
    }
   ],
   "source": [
    "# Define a query to be answered\n",
    "query = \"What did Emma share with the children during their visit?\"\n",
    "\n",
    "# Use the RetrievalQA chain to get an answer for the query\n",
    "result = qa.invoke(query)  # Invoke the QA system with the provided query\n",
    "\n",
    "# Print the result of the query\n",
    "print(result) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8b3fe5b-c925-4cd9-8bdf-d5aff2e4941c",
   "metadata": {},
   "source": [
    "## Let's try other examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dfa9fc32-baa9-44e7-a209-943f08f29b47",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Number of requested results 4 is greater than number of elements in index 2, updating n_results = 2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'query': 'How did the community garden contribute to the sense of camaraderie among the members?',\n",
       " 'result': \" The community garden contributed to the sense of camaraderie among the members by providing a shared space where people could come together and work on a common goal. By working together in the garden, members were able to build relationships and foster a sense of community. Additionally, the garden served as a venue for social gatherings, such as the picnic at the end of the field trip, where members could enjoy each other's company and share their harvests. This common space and shared activities helped to create a\"}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"How did the community garden contribute to the sense of camaraderie among the members?\"\n",
    "qa.invoke(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "02a2710f-9d4e-4261-93cd-f6723de53a35",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Number of requested results 4 is greater than number of elements in index 2, updating n_results = 2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'query': 'Why did the local school visit the community garden?',\n",
       " 'result': ' The local school visited the community garden for a field trip to learn about how plants grow and the importance of taking care of the environment.'}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"Why did the local school visit the community garden?\"\n",
    "qa.invoke(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47b30d70-f7e5-48e8-988f-ebff8d0ede2c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
